{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               index                                               text  label\n",
      "0     train_01_0_892  state alleged hacked sabata petros chale thirt...      1\n",
      "1    train_01_1_2714  chale allegedly chased group thirty people hac...      0\n",
      "2   train_01_10_2619     farmworkers strike resumed tuesday demands met      1\n",
      "3  train_01_100_2680  demonstrators filed permit hold rally saturday...      1\n",
      "4  train_01_101_3090  footage attack included pregnant woman hit pro...      1\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/Users/nitanshjain/Documents/Projects/CASE/codefiles/subtask_1_data/train_subtask1_preprocessed_1.csv')\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0\n",
      " 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0\n",
      " 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0\n",
      " 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0\n",
      " 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 0 0 1 1\n",
      " 0 1 1 0 0 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0\n",
      " 0 1 0 1 1 1 0]\n",
      "               index                                               text\n",
      "0    train_10_0_2136  movement catapulted headlines early august sem...\n",
      "1     train_10_1_350  several thousand protesters took streets six p...\n",
      "2   train_10_10_3104  protest saving medha life also preserving peop...\n",
      "3  train_10_100_1188  hong kong baptist university protest contrite ...\n",
      "4  train_10_100_1734  published saturday three february two thousand...\n"
     ]
    }
   ],
   "source": [
    "dev_df = pd.read_csv('/Users/nitanshjain/Documents/Projects/CASE/codefiles/subtask_1_data/dev_subtask1_preprocessed_1.csv')\n",
    "dev_df.head()\n",
    "\n",
    "dev_df_labels = pd.read_csv('/Users/nitanshjain/Documents/Projects/CASE/tanfiona CausalNewsCorpus master data-V2/dev_subtask1.csv')\n",
    "labels = dev_df_labels['label'].values\n",
    "del(dev_df_labels)\n",
    "print(labels)\n",
    "print(dev_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_size = 150\n",
    "window_size = 5\n",
    "min_word = 5\n",
    "down_sampling = 1e-2\n",
    "\n",
    "fast_text_model_train = FastText(train_df.text.tolist(),\n",
    "                      window=window_size,\n",
    "                      min_count=min_word,\n",
    "                      sample=down_sampling,\n",
    "                      workers=4,\n",
    "                      sg=1)\n",
    "\n",
    "fast_text_model_dev = FastText(dev_df.text.tolist(),\n",
    "                      window=window_size,\n",
    "                      min_count=min_word,\n",
    "                      sample=down_sampling,\n",
    "                      workers=4,\n",
    "                      sg=1)\n",
    "\n",
    "fast_text_model_train.save(\"/Users/nitanshjain/Documents/Projects/CASE/codefiles/subtask1_embeddings/ft_model_train_text_1\")\n",
    "fast_text_model_train = Word2Vec.load(\"/Users/nitanshjain/Documents/Projects/CASE/codefiles/subtask1_embeddings/ft_model_train_text_1\")\n",
    "\n",
    "fast_text_model_dev.save(\"/Users/nitanshjain/Documents/Projects/CASE/codefiles/subtask1_embeddings/ft_model_dev_text_1\")\n",
    "fast_text_model_dev = Word2Vec.load(\"/Users/nitanshjain/Documents/Projects/CASE/codefiles/subtask1_embeddings/ft_model_dev_text_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3075, 150)\n",
      "(340, 150)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.028195</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.035096</td>\n",
       "      <td>0.032376</td>\n",
       "      <td>0.021040</td>\n",
       "      <td>-0.035952</td>\n",
       "      <td>0.008841</td>\n",
       "      <td>0.098521</td>\n",
       "      <td>-0.058418</td>\n",
       "      <td>-0.045578</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.029227</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.036354</td>\n",
       "      <td>0.033353</td>\n",
       "      <td>0.019263</td>\n",
       "      <td>-0.038063</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.089704</td>\n",
       "      <td>-0.054878</td>\n",
       "      <td>-0.044369</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.029023</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.032971</td>\n",
       "      <td>0.036659</td>\n",
       "      <td>0.024971</td>\n",
       "      <td>-0.038789</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>0.090020</td>\n",
       "      <td>-0.059667</td>\n",
       "      <td>-0.041691</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.033026</td>\n",
       "      <td>0.009413</td>\n",
       "      <td>0.036592</td>\n",
       "      <td>0.027374</td>\n",
       "      <td>0.015940</td>\n",
       "      <td>-0.038907</td>\n",
       "      <td>0.012596</td>\n",
       "      <td>0.091721</td>\n",
       "      <td>-0.057417</td>\n",
       "      <td>-0.052107</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.029150</td>\n",
       "      <td>0.006021</td>\n",
       "      <td>0.034814</td>\n",
       "      <td>0.030217</td>\n",
       "      <td>0.020628</td>\n",
       "      <td>-0.040322</td>\n",
       "      <td>0.008536</td>\n",
       "      <td>0.100185</td>\n",
       "      <td>-0.060256</td>\n",
       "      <td>-0.045170</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \n",
       "0 -0.028195  0.007591  0.035096  0.032376  0.021040 -0.035952  0.008841  \\\n",
       "1 -0.029227  0.008621  0.036354  0.033353  0.019263 -0.038063  0.010679   \n",
       "2 -0.029023  0.006393  0.032971  0.036659  0.024971 -0.038789  0.005379   \n",
       "3 -0.033026  0.009413  0.036592  0.027374  0.015940 -0.038907  0.012596   \n",
       "4 -0.029150  0.006021  0.034814  0.030217  0.020628 -0.040322  0.008536   \n",
       "\n",
       "          7         8         9  ...  140  141  142  143  144  145  146  147   \n",
       "0  0.098521 -0.058418 -0.045578  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \\\n",
       "1  0.089704 -0.054878 -0.044369  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2  0.090020 -0.059667 -0.041691  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3  0.091721 -0.057417 -0.052107  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4  0.100185 -0.060256 -0.045170  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "   148  149  \n",
       "0  NaN  NaN  \n",
       "1  NaN  NaN  \n",
       "2  NaN  NaN  \n",
       "3  NaN  NaN  \n",
       "4  NaN  NaN  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_file(create_file, model_file, x):\n",
    "    fast_text_model = Word2Vec.load(model_file)\n",
    "    \n",
    "    with open(create_file, 'w+') as word2vec_file:\n",
    "        for index, row in x.iterrows():\n",
    "            model_vector = (np.mean([fast_text_model.wv[token] for token in row['text']], axis=0)).tolist()\n",
    "            if index == 0:\n",
    "                header = \",\".join(str(ele) for ele in range(150))\n",
    "                word2vec_file.write(header)\n",
    "                word2vec_file.write(\"\\n\")\n",
    "            \n",
    "            if type(model_vector) is list:\n",
    "                line1 = \",\".join( [str(vector_element) for vector_element in model_vector] )\n",
    "            else:\n",
    "                line1 = \",\".join([str(0) for i in range(150)])\n",
    "            word2vec_file.write(line1)\n",
    "            word2vec_file.write('\\n')\n",
    "    \n",
    "    df = pd.read_csv(create_file)\n",
    "    return df\n",
    "\n",
    "fast_text_train_filename = '/Users/nitanshjain/Documents/Projects/CASE/codefiles/subtask_1_data/train_ft_1.csv'\n",
    "fast_text_train_model_file = '/Users/nitanshjain/Documents/Projects/CASE/codefiles/subtask1_embeddings/ft_model_train_text_1'\n",
    "fast_text_train_embeddings_df = create_file(fast_text_train_filename, fast_text_train_model_file, train_df)\n",
    "\n",
    "fast_text_train_embeddings = fast_text_train_embeddings_df.values\n",
    "\n",
    "print(fast_text_train_embeddings_df.shape)\n",
    "fast_text_train_embeddings_df.head()\n",
    "\n",
    "\n",
    "fast_text_dev_filename = '/Users/nitanshjain/Documents/Projects/CASE/codefiles/subtask_1_data/dev_ft_1.csv'\n",
    "fast_text_dev_model_file = '/Users/nitanshjain/Documents/Projects/CASE/codefiles/subtask1_embeddings/ft_model_dev_text_1'\n",
    "fast_text_dev_embeddings_df = create_file(fast_text_dev_filename, fast_text_dev_model_file, dev_df)\n",
    "\n",
    "fast_text_dev_embeddings = fast_text_dev_embeddings_df.values\n",
    "\n",
    "print(fast_text_dev_embeddings_df.shape)\n",
    "fast_text_dev_embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fast_text_train_embeddings_df.values\n",
    "y = train_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "parameters = {\n",
    "            'objective':['binary:logistic'],\n",
    "            'learning_rate': [0.00001, 0.00005], \n",
    "            'max_depth': [6, 7, 8],\n",
    "            'min_child_weight': [11],\n",
    "            'subsample': [0.8],\n",
    "            'colsample_bytree': [0.7],\n",
    "            'n_estimators': [1000], #number of trees, change it to 1000 for better results\n",
    "            'seed': [1337]\n",
    "        }\n",
    "\n",
    "clf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "                   cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True), \n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clf.fit(x, y)\n",
    "print(clf.best_params_, clf.best_score_)\n",
    "\n",
    "x_dev = fast_text_dev_embeddings_df.values\n",
    "y_dev = labels\n",
    "\n",
    "y_pred = clf.predict(x_dev)\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - no stopwords and removed few abbreviations\n",
    "# 2 - with stopwords and removed few abbreviations\n",
    "# 3 - no stopwords and didnt remove abbreviations\n",
    "# 4 - with stopwords and didnt remove abbreviations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CASE-cD2HfaeL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
