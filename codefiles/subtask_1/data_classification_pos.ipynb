{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import spacy as sy\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "seed = 2000\n",
    "np.random.seed(seed)\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, MaxPooling1D, Dropout, Flatten, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "nlp_en = sy.load('en_core_web_sm')\n",
    "all_stopwords = nlp_en.Defaults.stop_words\n",
    "\n",
    "num_i = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               index                                               text  label\n",
      "0     train_01_0_892  the state alleged they hacked sabata petros ch...      1\n",
      "1    train_01_1_2714  chale was allegedly chased group about thirty ...      0\n",
      "2   train_01_10_2619  the farmworkers strike resumed tuesday when th...      1\n",
      "3  train_01_100_2680  demonstrators have filed for permit hold rally...      1\n",
      "4  train_01_101_3090  footage the attack which included pregnant wom...      1\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/Users/nitanshjain/Documents/Projects/CASE/codefiles/subtask_1_data/train_subtask1_preprocessed_{}.csv'.format(num_i))\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0\n",
      " 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0\n",
      " 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0\n",
      " 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0\n",
      " 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 0 0 1 1\n",
      " 0 1 1 0 0 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0\n",
      " 0 1 0 1 1 1 0]\n",
      "               index                                               text\n",
      "0    train_10_0_2136  the movement was catapulted into the headlines...\n",
      "1     train_10_1_350  several thousand protesters took the streets a...\n",
      "2   train_10_10_3104  the protest not just about saving medha life b...\n",
      "3  train_10_100_1188  hong kong baptist university protest contrite ...\n",
      "4  train_10_100_1734  published saturday three february two thousand...\n"
     ]
    }
   ],
   "source": [
    "dev_df = pd.read_csv('/Users/nitanshjain/Documents/Projects/CASE/codefiles/subtask_1_data/dev_subtask1_preprocessed_{}.csv'.format(num_i))\n",
    "dev_df.head()\n",
    "\n",
    "dev_df_labels = pd.read_csv('/Users/nitanshjain/Documents/Projects/CASE/tanfiona CausalNewsCorpus master data-V2/dev_subtask1.csv')\n",
    "labels = dev_df_labels['label'].values\n",
    "del(dev_df_labels)\n",
    "print(labels)\n",
    "print(dev_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>pos_tags_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_01_0_892</td>\n",
       "      <td>the state alleged they hacked sabata petros ch...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'NN': 6, 'NNP': 7, 'CD': 7}</td>\n",
       "      <td>{'NN': 0.3333333333333333, 'NNP': 0.3333333333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_01_1_2714</td>\n",
       "      <td>chale was allegedly chased group about thirty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'NN': 4, 'NNS': 3}</td>\n",
       "      <td>{'NN': 0.5, 'NNS': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_01_10_2619</td>\n",
       "      <td>the farmworkers strike resumed tuesday when th...</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_01_100_2680</td>\n",
       "      <td>demonstrators have filed for permit hold rally...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'NNS': 8, 'NN': 6, 'NNP': 4, 'VBD': 3, 'CC': 3}</td>\n",
       "      <td>{'NNS': 0.2, 'NN': 0.2, 'NNP': 0.2, 'VBD': 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_01_101_3090</td>\n",
       "      <td>footage the attack which included pregnant wom...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'NN': 8, 'VBD': 3, 'JJ': 3, 'VBG': 7, 'NNS': ...</td>\n",
       "      <td>{'NN': 0.14285714285714285, 'VBD': 0.142857142...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index                                               text  \\\n",
       "0     train_01_0_892  the state alleged they hacked sabata petros ch...   \n",
       "1    train_01_1_2714  chale was allegedly chased group about thirty ...   \n",
       "2   train_01_10_2619  the farmworkers strike resumed tuesday when th...   \n",
       "3  train_01_100_2680  demonstrators have filed for permit hold rally...   \n",
       "4  train_01_101_3090  footage the attack which included pregnant wom...   \n",
       "\n",
       "   label                                           pos_tags  \\\n",
       "0      1                       {'NN': 6, 'NNP': 7, 'CD': 7}   \n",
       "1      0                                {'NN': 4, 'NNS': 3}   \n",
       "2      1                                                 {}   \n",
       "3      1   {'NNS': 8, 'NN': 6, 'NNP': 4, 'VBD': 3, 'CC': 3}   \n",
       "4      1  {'NN': 8, 'VBD': 3, 'JJ': 3, 'VBG': 7, 'NNS': ...   \n",
       "\n",
       "                                       pos_tags_prob  \n",
       "0  {'NN': 0.3333333333333333, 'NNP': 0.3333333333...  \n",
       "1                            {'NN': 0.5, 'NNS': 0.5}  \n",
       "2                                                 {}  \n",
       "3  {'NNS': 0.2, 'NN': 0.2, 'NNP': 0.2, 'VBD': 0.2...  \n",
       "4  {'NN': 0.14285714285714285, 'VBD': 0.142857142...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_pos_tags(text, min_threshold):\n",
    "    doc = nlp_en(text)\n",
    "    pos_tags = [(i.tag_) for i in doc]\n",
    "    pos_tags = Counter(pos_tags)\n",
    "    pos_tags = {x: count for x, count in pos_tags.items() if count > min_threshold}\n",
    "    return pos_tags\n",
    "\n",
    "def generate_tokens_prob_freq(tokens):\n",
    "    dct={}\n",
    "    for i in tokens:\n",
    "        dct[i]=0\n",
    "    for i in tokens:\n",
    "        dct[i]+=1\n",
    "    prob_freq = {key:float(value)/sum(dct.values()) for (key,value) in dct.items()}\n",
    "    \n",
    "    return prob_freq\n",
    "\n",
    "train_df['pos_tags'] = train_df['text'].apply(lambda x: generate_pos_tags(x, 2))\n",
    "dev_df['pos_tags'] = train_df['text'].apply(lambda x : generate_pos_tags(x, 2))\n",
    "train_df['pos_tags_prob'] = train_df['pos_tags'].apply(lambda x: generate_tokens_prob_freq(x))\n",
    "dev_df['pos_tags_prob'] = dev_df['pos_tags'].apply(lambda x: generate_tokens_prob_freq(x))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         NN       NNP        CD       NNS       VBD        CC        JJ  \\\n",
      "0  0.333333  0.333333  0.333333  0.000000  0.000000  0.000000  0.000000   \n",
      "1  0.500000  0.000000  0.000000  0.500000  0.000000  0.000000  0.000000   \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3  0.200000  0.200000  0.000000  0.200000  0.200000  0.200000  0.000000   \n",
      "4  0.142857  0.000000  0.000000  0.142857  0.142857  0.142857  0.142857   \n",
      "\n",
      "        VBG        IN   DT  ...   VB   RB  VBP  VBN  VBZ  PRP$  HYPH  PRP  \\\n",
      "0  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   \n",
      "1  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   \n",
      "2  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   \n",
      "3  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   \n",
      "4  0.142857  0.142857  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   \n",
      "\n",
      "    MD  JJR  \n",
      "0  0.0  0.0  \n",
      "1  0.0  0.0  \n",
      "2  0.0  0.0  \n",
      "3  0.0  0.0  \n",
      "4  0.0  0.0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "         NN       NNP        CD       NNS       VBD        CC        JJ  \\\n",
      "0  0.333333  0.333333  0.333333  0.000000  0.000000  0.000000  0.000000   \n",
      "1  0.500000  0.000000  0.000000  0.500000  0.000000  0.000000  0.000000   \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3  0.200000  0.200000  0.000000  0.200000  0.200000  0.200000  0.000000   \n",
      "4  0.142857  0.000000  0.000000  0.142857  0.142857  0.142857  0.142857   \n",
      "\n",
      "        VBG        IN   DT  WDT   VB   RB  VBP  VBN  VBZ  PRP$  HYPH  \n",
      "0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
      "1  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
      "2  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
      "3  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
      "4  0.142857  0.142857  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n"
     ]
    }
   ],
   "source": [
    "train_df_pos_prob = pd.json_normalize(train_df['pos_tags_prob'])\n",
    "dev_df_pos_prob = pd.json_normalize(dev_df['pos_tags_prob'])\n",
    "train_df_pos_prob.replace(np.nan, 0, inplace=True)\n",
    "dev_df_pos_prob.replace(np.nan, 0, inplace=True)\n",
    "print(train_df_pos_prob.head())\n",
    "print(dev_df_pos_prob.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3075, 21)\n",
      "(340, 18)\n",
      "Index(['NN', 'NNP', 'CD', 'NNS', 'VBD', 'CC', 'JJ', 'VBG', 'IN', 'DT', 'WDT',\n",
      "       'VB', 'RB', 'VBP', 'VBN', 'VBZ', 'PRP$', 'HYPH', 'PRP', 'MD', 'JJR'],\n",
      "      dtype='object')\n",
      "Index(['NN', 'NNP', 'CD', 'NNS', 'VBD', 'CC', 'JJ', 'VBG', 'IN', 'DT', 'WDT',\n",
      "       'VB', 'RB', 'VBP', 'VBN', 'VBZ', 'PRP$', 'HYPH'],\n",
      "      dtype='object')\n",
      "['PRP', 'JJR', 'MD']\n",
      "(3075, 21)\n",
      "(340, 21)\n"
     ]
    }
   ],
   "source": [
    "print(train_df_pos_prob.shape)\n",
    "print(dev_df_pos_prob.shape)\n",
    "print(train_df_pos_prob.columns)\n",
    "print(dev_df_pos_prob.columns)\n",
    "\n",
    "columns = list(set(train_df_pos_prob.columns) - set(dev_df_pos_prob.columns))\n",
    "print(columns)\n",
    "\n",
    "for col_name in columns:\n",
    "    if col_name not in train_df_pos_prob.columns:\n",
    "        train_df_pos_prob[col_name]=0\n",
    "\n",
    "    if col_name not in dev_df_pos_prob.columns:\n",
    "        dev_df_pos_prob[col_name]=0\n",
    "        \n",
    "print(train_df_pos_prob.shape)\n",
    "print(dev_df_pos_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.0596140592694694, 1: 0.9467364532019704} 0.8934729064039408\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x = train_df_pos_prob.values\n",
    "x = scaler.fit_transform(x)\n",
    "y = train_df['label'].values\n",
    "\n",
    "x_dev = dev_df_pos_prob.values\n",
    "y_dev = labels\n",
    "\n",
    "# Calculating Classweights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight = \"balanced\",\n",
    "    classes = np.unique(y),\n",
    "    y = y\n",
    ")\n",
    "class_weights = dict(zip(np.unique(y), class_weights))\n",
    "\n",
    "count_0 = np.unique(y, return_counts=True)[1][0]\n",
    "count_1 = np.unique(y, return_counts=True)[1][1]\n",
    "estimate = count_0/count_1\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
    "\n",
    "print(class_weights, estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 1000, 'objective': 'binary:logistic', 'seed': 1337} 0.6081300813008129\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.51      0.47       155\n",
      "           1       0.52      0.45      0.48       185\n",
      "\n",
      "    accuracy                           0.48       340\n",
      "   macro avg       0.48      0.48      0.48       340\n",
      "weighted avg       0.48      0.48      0.48       340\n",
      "\n",
      "0.48255813953488375\n",
      "0.4486486486486487\n",
      "0.5220125786163522\n",
      "-0.041598564339664246\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(scale_pos_weight=estimate)\n",
    "\n",
    "parameters = {\n",
    "            'objective':['binary:logistic'],\n",
    "            'learning_rate': [0.1, 0.01, 0.001, 0.0001], \n",
    "            'max_depth': [5, 6, 7, 8],\n",
    "            'n_estimators': [1000], #number of trees, change it to 1000 for better results\n",
    "            'seed': [1337]\n",
    "        }\n",
    "\n",
    "clf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "                   cv=cv, \n",
    "                   verbose=0, refit=True)\n",
    "\n",
    "clf.fit(x, y)\n",
    "print(clf.best_params_, clf.best_score_)\n",
    "\n",
    "y_pred = clf.predict(x_dev)\n",
    "print(classification_report(y_dev, y_pred))\n",
    "print(f1_score(y_dev, y_pred))\n",
    "print(recall_score(y_dev, y_pred))\n",
    "print(precision_score(y_dev, y_pred))\n",
    "print(matthews_corrcoef(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_prior': None, 'fit_prior': False} 0.5899186991869918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.52      0.48       155\n",
      "           1       0.53      0.45      0.49       185\n",
      "\n",
      "    accuracy                           0.49       340\n",
      "   macro avg       0.49      0.49      0.49       340\n",
      "weighted avg       0.49      0.49      0.49       340\n",
      "\n",
      "0.489795918367347\n",
      "0.4540540540540541\n",
      "0.5316455696202531\n",
      "-0.023332369848381523\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "parameters = {\n",
    "            'fit_prior': [True, False],\n",
    "            'class_prior': [None, [0.5, 0.5], [0.6, 0.4], [0.4, 0.6]]\n",
    "        }\n",
    "\n",
    "mnb_gsc = GridSearchCV(mnb, parameters, n_jobs=5, \n",
    "                   cv=cv, \n",
    "                   verbose=0, refit=True)\n",
    "\n",
    "mnb_gsc.fit(x, y)\n",
    "print(mnb_gsc.best_params_, mnb_gsc.best_score_)\n",
    "\n",
    "y_pred = mnb_gsc.predict(x_dev)\n",
    "print(classification_report(y_dev, y_pred))\n",
    "print(f1_score(y_dev, y_pred))\n",
    "print(recall_score(y_dev, y_pred))\n",
    "print(precision_score(y_dev, y_pred))\n",
    "print(matthews_corrcoef(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_f1(y_true, y_pred):\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    \n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2 * (precision * recall)/(precision + recall + K.epsilon())\n",
    "    \n",
    "    return f1_val\n",
    "\n",
    "x = x[:,:,None]\n",
    "\n",
    "red_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", \n",
    "            factor=0.6,\n",
    "            patience=2, \n",
    "            min_lr=0.0001,\n",
    "            verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 21, 64)            16896     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,145\n",
      "Trainable params: 54,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "\n",
    "model_lstm.add(LSTM(64, input_shape = x.shape[1:], return_sequences = True))\n",
    "model_lstm.add(LSTM(64))\n",
    "\n",
    "model_lstm.add(Dense(64, activation = 'relu'))\n",
    "model_lstm.add(Flatten())\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_lstm.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics = [binary_f1])\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 9s 88ms/step - loss: 0.6932 - binary_f1: 0.2788 - val_loss: 0.6921 - val_binary_f1: 0.6800 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.6925 - binary_f1: 0.6814 - val_loss: 0.6963 - val_binary_f1: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 0.6940 - binary_f1: 0.0037\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.6940 - binary_f1: 0.0034 - val_loss: 0.6939 - val_binary_f1: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.6919 - binary_f1: 0.0096 - val_loss: 0.6944 - val_binary_f1: 0.0084 - lr: 6.0000e-04\n",
      "Epoch 5/20\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 0.6878 - binary_f1: 0.2867\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.6880 - binary_f1: 0.3237 - val_loss: 0.6982 - val_binary_f1: 0.6818 - lr: 6.0000e-04\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.6858 - binary_f1: 0.6989 - val_loss: 0.7057 - val_binary_f1: 0.6686 - lr: 3.6000e-04\n",
      "Epoch 7/20\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 0.6826 - binary_f1: 0.6941\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.6831 - binary_f1: 0.6974 - val_loss: 0.6964 - val_binary_f1: 0.6800 - lr: 3.6000e-04\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.6829 - binary_f1: 0.6994 - val_loss: 0.6995 - val_binary_f1: 0.6818 - lr: 2.1600e-04\n",
      "Epoch 9/20\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 0.6822 - binary_f1: 0.6957\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.6823 - binary_f1: 0.6883 - val_loss: 0.7007 - val_binary_f1: 0.6818 - lr: 2.1600e-04\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.6822 - binary_f1: 0.7078 - val_loss: 0.7012 - val_binary_f1: 0.6818 - lr: 1.2960e-04\n",
      "Epoch 11/20\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 0.6825 - binary_f1: 0.6942\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.6823 - binary_f1: 0.6947 - val_loss: 0.7013 - val_binary_f1: 0.6818 - lr: 1.2960e-04\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 1s 37ms/step - loss: 0.6828 - binary_f1: 0.7066 - val_loss: 0.6959 - val_binary_f1: 0.6800 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.6821 - binary_f1: 0.6936 - val_loss: 0.7024 - val_binary_f1: 0.6818 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.6825 - binary_f1: 0.6991 - val_loss: 0.7053 - val_binary_f1: 0.6818 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.6818 - binary_f1: 0.6991 - val_loss: 0.6982 - val_binary_f1: 0.6800 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.6818 - binary_f1: 0.6882 - val_loss: 0.7003 - val_binary_f1: 0.6818 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.6815 - binary_f1: 0.7071 - val_loss: 0.7015 - val_binary_f1: 0.6818 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.6820 - binary_f1: 0.6875 - val_loss: 0.7024 - val_binary_f1: 0.6818 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.6813 - binary_f1: 0.7073 - val_loss: 0.7008 - val_binary_f1: 0.6818 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.6811 - binary_f1: 0.6994 - val_loss: 0.7040 - val_binary_f1: 0.6818 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x169a4baf0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "model_lstm.fit(x, y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=20,\n",
    "            validation_data=(x_dev, y_dev),\n",
    "            class_weight=class_weights,\n",
    "            shuffle=True, \n",
    "            callbacks=[red_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.13      0.21       155\n",
      "           1       0.55      0.90      0.69       185\n",
      "\n",
      "    accuracy                           0.55       340\n",
      "   macro avg       0.54      0.52      0.45       340\n",
      "weighted avg       0.54      0.55      0.47       340\n",
      "\n",
      "0.6858316221765914\n",
      "0.9027027027027027\n",
      "0.5529801324503312\n",
      "0.05016425989944509\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_lstm.predict(x_dev)\n",
    "y_pred_final = np.where(y_pred > 0.5, 1, 0)\n",
    "print(classification_report(y_dev, y_pred_final))\n",
    "print(f1_score(y_dev, y_pred_final))\n",
    "print(recall_score(y_dev, y_pred_final))\n",
    "print(precision_score(y_dev, y_pred_final))\n",
    "print(matthews_corrcoef(y_dev, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirectio  (3075, 21, 128)          33792     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (3075, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (3075, 64)                8256      \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (3075, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (3075, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140,929\n",
      "Trainable params: 140,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm  =  Sequential()\n",
    "\n",
    "model_bilstm.add(Bidirectional(LSTM(64, input_shape = x.shape[1:], return_sequences=True)))\n",
    "model_bilstm.add(Bidirectional(LSTM(64)))\n",
    "\n",
    "model_bilstm.add(Dense(64, activation = 'relu'))\n",
    "model_bilstm.add(Flatten())\n",
    "model_bilstm.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model_bilstm.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics = [binary_f1])\n",
    "model_bilstm.build(input_shape=x.shape)\n",
    "model_bilstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 17s 161ms/step - loss: 0.6933 - binary_f1: 0.2366 - val_loss: 0.6922 - val_binary_f1: 0.6800 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 0.6927 - binary_f1: 0.2110 - val_loss: 0.6910 - val_binary_f1: 0.6800 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 60ms/step - loss: 0.6896 - binary_f1: 0.5692 - val_loss: 0.6925 - val_binary_f1: 0.7007 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.6928 - binary_f1: 0.6795\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 0.6929 - binary_f1: 0.6524 - val_loss: 0.6952 - val_binary_f1: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 0.6874 - binary_f1: 0.4140 - val_loss: 0.6943 - val_binary_f1: 0.6097 - lr: 6.0000e-04\n",
      "Epoch 6/20\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.6823 - binary_f1: 0.6469\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 0.6823 - binary_f1: 0.6477 - val_loss: 0.7258 - val_binary_f1: 0.2249 - lr: 6.0000e-04\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 60ms/step - loss: 0.6845 - binary_f1: 0.5663 - val_loss: 0.6941 - val_binary_f1: 0.6536 - lr: 3.6000e-04\n",
      "Epoch 8/20\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.6800 - binary_f1: 0.6074\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.6801 - binary_f1: 0.5831 - val_loss: 0.7004 - val_binary_f1: 0.6064 - lr: 3.6000e-04\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.6783 - binary_f1: 0.6394 - val_loss: 0.7079 - val_binary_f1: 0.5721 - lr: 2.1600e-04\n",
      "Epoch 10/20\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.6786 - binary_f1: 0.6221\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.6786 - binary_f1: 0.5973 - val_loss: 0.7072 - val_binary_f1: 0.5892 - lr: 2.1600e-04\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 0.6777 - binary_f1: 0.6121 - val_loss: 0.7086 - val_binary_f1: 0.5769 - lr: 1.2960e-04\n",
      "Epoch 12/20\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.6793 - binary_f1: 0.5809\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "25/25 [==============================] - 2s 60ms/step - loss: 0.6790 - binary_f1: 0.5977 - val_loss: 0.7064 - val_binary_f1: 0.5892 - lr: 1.2960e-04\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.6774 - binary_f1: 0.6619 - val_loss: 0.7092 - val_binary_f1: 0.5944 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 0.6781 - binary_f1: 0.6270 - val_loss: 0.7079 - val_binary_f1: 0.5987 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.6774 - binary_f1: 0.6669 - val_loss: 0.7069 - val_binary_f1: 0.6064 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 0.6777 - binary_f1: 0.6074 - val_loss: 0.7064 - val_binary_f1: 0.5944 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 60ms/step - loss: 0.6769 - binary_f1: 0.6027 - val_loss: 0.7103 - val_binary_f1: 0.5721 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.6775 - binary_f1: 0.5948 - val_loss: 0.7090 - val_binary_f1: 0.5769 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 0.6777 - binary_f1: 0.6212 - val_loss: 0.7080 - val_binary_f1: 0.5769 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 60ms/step - loss: 0.6768 - binary_f1: 0.6396 - val_loss: 0.7058 - val_binary_f1: 0.5925 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16273fee0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "model_bilstm.fit(x, y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=20,\n",
    "            validation_data=(x_dev, y_dev),\n",
    "            class_weight=class_weights,\n",
    "            shuffle=True,\n",
    "            callbacks=[red_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.40      0.44       155\n",
      "           1       0.56      0.64      0.60       185\n",
      "\n",
      "    accuracy                           0.53       340\n",
      "   macro avg       0.52      0.52      0.52       340\n",
      "weighted avg       0.52      0.53      0.52       340\n",
      "\n",
      "0.595959595959596\n",
      "0.6378378378378379\n",
      "0.5592417061611374\n",
      "0.03883666618024915\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_bilstm.predict(x_dev)\n",
    "y_pred_final = np.where(y_pred > 0.5, 1, 0)\n",
    "print(classification_report(y_dev, y_pred_final))\n",
    "print(f1_score(y_dev, y_pred_final))\n",
    "print(recall_score(y_dev, y_pred_final))\n",
    "print(precision_score(y_dev, y_pred_final))\n",
    "print(matthews_corrcoef(y_dev, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CASE-cD2HfaeL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
