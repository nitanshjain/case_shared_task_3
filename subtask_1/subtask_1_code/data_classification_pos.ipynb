{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-16 01:56:49.122223: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import spacy as sy\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "seed = 2000\n",
    "np.random.seed(seed)\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, MaxPooling1D, Dropout, Flatten, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "nlp_en = sy.load('en_core_web_sm')\n",
    "all_stopwords = nlp_en.Defaults.stop_words\n",
    "\n",
    "num_i = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3415, 3)\n",
      "               index                                               text  label\n",
      "0     train_01_0_892  the state alleged they hacked sabata petros ch...      1\n",
      "1    train_01_1_2714  chale was allegedly chased group about thirty ...      0\n",
      "2   train_01_10_2619  the farmworkers strike resumed tuesday when th...      1\n",
      "3  train_01_100_2680  demonstrators have filed for permit hold rally...      1\n",
      "4  train_01_101_3090  footage the attack which included pregnant wom...      1\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/Users/nitanshjain/Documents/Projects/CASE/subtask_1/subtask_1_data/train_subtask1_test_preprocessed_{}.csv'.format(num_i))\n",
    "print(train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_01_A_0_271</td>\n",
       "      <td>more than twenty associate degree students mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_01_A_1_215</td>\n",
       "      <td>more than ten people from the rights associati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_01_A_10_198</td>\n",
       "      <td>the organisation has been spearheading agitati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_01_A_100_277</td>\n",
       "      <td>not believe politicians that they will achieve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_01_A_101_152</td>\n",
       "      <td>for that matter haragopal himself took proacti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index                                               text\n",
       "0    test_01_A_0_271  more than twenty associate degree students mar...\n",
       "1    test_01_A_1_215  more than ten people from the rights associati...\n",
       "2   test_01_A_10_198  the organisation has been spearheading agitati...\n",
       "3  test_01_A_100_277  not believe politicians that they will achieve...\n",
       "4  test_01_A_101_152  for that matter haragopal himself took proacti..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('/Users/nitanshjain/Documents/Projects/CASE/subtask_1/subtask_1_data/test_subtask1_test_preprocessed_{}.csv'.format(num_i))\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>pos_tags_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_01_0_892</td>\n",
       "      <td>the state alleged they hacked sabata petros ch...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'NN': 6, 'NNP': 7, 'CD': 7}</td>\n",
       "      <td>{'NN': 0.3333333333333333, 'NNP': 0.3333333333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_01_1_2714</td>\n",
       "      <td>chale was allegedly chased group about thirty ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'NN': 4, 'NNS': 3}</td>\n",
       "      <td>{'NN': 0.5, 'NNS': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_01_10_2619</td>\n",
       "      <td>the farmworkers strike resumed tuesday when th...</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_01_100_2680</td>\n",
       "      <td>demonstrators have filed for permit hold rally...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'NNS': 8, 'NN': 6, 'NNP': 4, 'VBD': 3, 'CC': 3}</td>\n",
       "      <td>{'NNS': 0.2, 'NN': 0.2, 'NNP': 0.2, 'VBD': 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_01_101_3090</td>\n",
       "      <td>footage the attack which included pregnant wom...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'NN': 8, 'VBD': 3, 'JJ': 3, 'VBG': 7, 'NNS': ...</td>\n",
       "      <td>{'NN': 0.14285714285714285, 'VBD': 0.142857142...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index                                               text  \\\n",
       "0     train_01_0_892  the state alleged they hacked sabata petros ch...   \n",
       "1    train_01_1_2714  chale was allegedly chased group about thirty ...   \n",
       "2   train_01_10_2619  the farmworkers strike resumed tuesday when th...   \n",
       "3  train_01_100_2680  demonstrators have filed for permit hold rally...   \n",
       "4  train_01_101_3090  footage the attack which included pregnant wom...   \n",
       "\n",
       "   label                                           pos_tags  \\\n",
       "0      1                       {'NN': 6, 'NNP': 7, 'CD': 7}   \n",
       "1      0                                {'NN': 4, 'NNS': 3}   \n",
       "2      1                                                 {}   \n",
       "3      1   {'NNS': 8, 'NN': 6, 'NNP': 4, 'VBD': 3, 'CC': 3}   \n",
       "4      1  {'NN': 8, 'VBD': 3, 'JJ': 3, 'VBG': 7, 'NNS': ...   \n",
       "\n",
       "                                       pos_tags_prob  \n",
       "0  {'NN': 0.3333333333333333, 'NNP': 0.3333333333...  \n",
       "1                            {'NN': 0.5, 'NNS': 0.5}  \n",
       "2                                                 {}  \n",
       "3  {'NNS': 0.2, 'NN': 0.2, 'NNP': 0.2, 'VBD': 0.2...  \n",
       "4  {'NN': 0.14285714285714285, 'VBD': 0.142857142...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_pos_tags(text, min_threshold):\n",
    "    doc = nlp_en(text)\n",
    "    pos_tags = [(i.tag_) for i in doc]\n",
    "    pos_tags = Counter(pos_tags)\n",
    "    pos_tags = {x: count for x, count in pos_tags.items() if count > min_threshold}\n",
    "    return pos_tags\n",
    "\n",
    "def generate_tokens_prob_freq(tokens):\n",
    "    dct={}\n",
    "    for i in tokens:\n",
    "        dct[i]=0\n",
    "    for i in tokens:\n",
    "        dct[i]+=1\n",
    "    prob_freq = {key:float(value)/sum(dct.values()) for (key,value) in dct.items()}\n",
    "    \n",
    "    return prob_freq\n",
    "\n",
    "train_df['pos_tags'] = train_df['text'].apply(lambda x: generate_pos_tags(x, 2))\n",
    "test_df['pos_tags'] = train_df['text'].apply(lambda x : generate_pos_tags(x, 2))\n",
    "train_df['pos_tags_prob'] = train_df['pos_tags'].apply(lambda x: generate_tokens_prob_freq(x))\n",
    "test_df['pos_tags_prob'] = test_df['pos_tags'].apply(lambda x: generate_tokens_prob_freq(x))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         NN       NNP        CD       NNS       VBD        CC        JJ  \\\n",
      "0  0.333333  0.333333  0.333333  0.000000  0.000000  0.000000  0.000000   \n",
      "1  0.500000  0.000000  0.000000  0.500000  0.000000  0.000000  0.000000   \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3  0.200000  0.200000  0.000000  0.200000  0.200000  0.200000  0.000000   \n",
      "4  0.142857  0.000000  0.000000  0.142857  0.142857  0.142857  0.142857   \n",
      "\n",
      "        VBG        IN   DT  ...   RB  VBP  VBN  VBZ  PRP$  HYPH  PRP   MD  \\\n",
      "0  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   \n",
      "1  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   \n",
      "2  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   \n",
      "3  0.000000  0.000000  0.0  ...  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   \n",
      "4  0.142857  0.142857  0.0  ...  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   \n",
      "\n",
      "   JJR  WRB  \n",
      "0  0.0  0.0  \n",
      "1  0.0  0.0  \n",
      "2  0.0  0.0  \n",
      "3  0.0  0.0  \n",
      "4  0.0  0.0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "         NN       NNP        CD       NNS       VBD        CC        JJ  \\\n",
      "0  0.333333  0.333333  0.333333  0.000000  0.000000  0.000000  0.000000   \n",
      "1  0.500000  0.000000  0.000000  0.500000  0.000000  0.000000  0.000000   \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3  0.200000  0.200000  0.000000  0.200000  0.200000  0.200000  0.000000   \n",
      "4  0.142857  0.000000  0.000000  0.142857  0.142857  0.142857  0.142857   \n",
      "\n",
      "        VBG        IN   DT  WDT   VB   RB  VBP  VBN  VBZ  PRP$  HYPH  \n",
      "0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
      "1  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
      "2  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
      "3  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
      "4  0.142857  0.142857  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n"
     ]
    }
   ],
   "source": [
    "train_df_pos_prob = pd.json_normalize(train_df['pos_tags_prob'])\n",
    "test_df_pos_prob = pd.json_normalize(test_df['pos_tags_prob'])\n",
    "train_df_pos_prob.replace(np.nan, 0, inplace=True)\n",
    "test_df_pos_prob.replace(np.nan, 0, inplace=True)\n",
    "print(train_df_pos_prob.head())\n",
    "print(test_df_pos_prob.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3415, 22)\n",
      "(352, 18)\n",
      "Index(['NN', 'NNP', 'CD', 'NNS', 'VBD', 'CC', 'JJ', 'VBG', 'IN', 'DT', 'WDT',\n",
      "       'VB', 'RB', 'VBP', 'VBN', 'VBZ', 'PRP$', 'HYPH', 'PRP', 'MD', 'JJR',\n",
      "       'WRB'],\n",
      "      dtype='object')\n",
      "Index(['NN', 'NNP', 'CD', 'NNS', 'VBD', 'CC', 'JJ', 'VBG', 'IN', 'DT', 'WDT',\n",
      "       'VB', 'RB', 'VBP', 'VBN', 'VBZ', 'PRP$', 'HYPH'],\n",
      "      dtype='object')\n",
      "['JJR', 'PRP', 'MD', 'WRB']\n",
      "(3415, 22)\n",
      "(352, 22)\n"
     ]
    }
   ],
   "source": [
    "print(train_df_pos_prob.shape)\n",
    "print(test_df_pos_prob.shape)\n",
    "print(train_df_pos_prob.columns)\n",
    "print(test_df_pos_prob.columns)\n",
    "\n",
    "columns = list(set(train_df_pos_prob.columns) - set(test_df_pos_prob.columns))\n",
    "print(columns)\n",
    "\n",
    "for col_name in columns:\n",
    "    if col_name not in train_df_pos_prob.columns:\n",
    "        train_df_pos_prob[col_name]=0\n",
    "\n",
    "    if col_name not in test_df_pos_prob.columns:\n",
    "        test_df_pos_prob[col_name]=0\n",
    "        \n",
    "print(train_df_pos_prob.shape)\n",
    "print(test_df_pos_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.063200498132005, 1: 0.9438916528468767} 0.8877833056937534\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x = train_df_pos_prob.values\n",
    "x = scaler.fit_transform(x)\n",
    "y = train_df['label'].values\n",
    "\n",
    "x_test = test_df_pos_prob.values\n",
    "# y_test = labels\n",
    "\n",
    "# Calculating Classweights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight = \"balanced\",\n",
    "    classes = np.unique(y),\n",
    "    y = y\n",
    ")\n",
    "class_weights = dict(zip(np.unique(y), class_weights))\n",
    "\n",
    "count_0 = np.unique(y, return_counts=True)[1][0]\n",
    "count_1 = np.unique(y, return_counts=True)[1][1]\n",
    "estimate = count_0/count_1\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
    "\n",
    "print(class_weights, estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(scale_pos_weight=estimate)\n",
    "\n",
    "parameters = {\n",
    "            'objective':['binary:logistic'],\n",
    "            'learning_rate': [0.1, 0.01, 0.001, 0.0001], \n",
    "            'max_depth': [5, 6, 7, 8],\n",
    "            'n_estimators': [1000], #number of trees, change it to 1000 for better results\n",
    "            'seed': [1337]\n",
    "        }\n",
    "\n",
    "clf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "                   cv=cv, \n",
    "                   verbose=0, refit=True)\n",
    "\n",
    "clf.fit(x, y)\n",
    "print(clf.best_params_, clf.best_score_)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# index = pd.Series(list(range(0,340)))\n",
    "index = pd.Series(test_df['index'])\n",
    "prediction = pd.Series(y_pred.reshape(352))\n",
    "submission_df = pd.concat([index,prediction], axis=1)\n",
    "submission_df.rename(columns = {0:'prediction'}, inplace = True)\n",
    "# submission_json = submission_df.to_json()\n",
    "\n",
    "converted_data = []\n",
    "for row in submission_df.itertuples(index=False):\n",
    "    entry = {\n",
    "        'index': row.index,\n",
    "        'prediction': row.prediction\n",
    "    }\n",
    "    converted_data.append(entry)\n",
    "converted_data\n",
    "\n",
    "# # Syntax of json.dumps() function\n",
    "import json\n",
    "with open(f'/Users/nitanshjain/Documents/Projects/CASE/subtask_1/subtask_1_results/submission_pos_xgb_1.json', 'w') as fp:\n",
    "    fp.write('\\n'.join(json.dumps(i) for i in converted_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_prior': None, 'fit_prior': False} 0.5827234652746811\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "parameters = {\n",
    "            'fit_prior': [True, False],\n",
    "            'class_prior': [None, [0.5, 0.5], [0.6, 0.4], [0.4, 0.6]]\n",
    "        }\n",
    "\n",
    "mnb_gsc = GridSearchCV(mnb, parameters, n_jobs=5, \n",
    "                   cv=cv, \n",
    "                   verbose=0, refit=True)\n",
    "\n",
    "mnb_gsc.fit(x, y)\n",
    "print(mnb_gsc.best_params_, mnb_gsc.best_score_)\n",
    "\n",
    "y_pred = mnb_gsc.predict(x_test)\n",
    "\n",
    "# index = pd.Series(list(range(0,340)))\n",
    "index = pd.Series(test_df['index'])\n",
    "prediction = pd.Series(y_pred.reshape(352))\n",
    "submission_df = pd.concat([index,prediction], axis=1)\n",
    "submission_df.rename(columns = {0:'prediction'}, inplace = True)\n",
    "# submission_json = submission_df.to_json()\n",
    "\n",
    "converted_data = []\n",
    "for row in submission_df.itertuples(index=False):\n",
    "    entry = {\n",
    "        'index': row.index,\n",
    "        'prediction': row.prediction\n",
    "    }\n",
    "    converted_data.append(entry)\n",
    "converted_data\n",
    "\n",
    "# # Syntax of json.dumps() function\n",
    "import json\n",
    "with open(f'/Users/nitanshjain/Documents/Projects/CASE/subtask_1/subtask_1_results/submission_pos_mnb_1.json', 'w') as fp:\n",
    "    fp.write('\\n'.join(json.dumps(i) for i in converted_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CASE-cD2HfaeL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
